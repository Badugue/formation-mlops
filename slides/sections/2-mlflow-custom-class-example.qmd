## Context

- [**NACE**]{.orange}
  - European standard classification of productive [**economic activities**]{.blue2}
  - [**Hierarchical structure**]{.blue2} with 4 levels and 615 codes

- At Insee, previously handled by an outdated [**rule-based**]{.orange} algorithm

- [**Common problematic**]{.orange} to many National Statistical Institutes

## Fasttext 

- [**"Bag of n-gram model"**]{.orange} : embeddings for words but also n-gram of words and characters
- Very [**simple**]{.orange} and [**fast**]{.orange} model

![](img/diag-fasttext.png){fig-align="center"}

## Data used {.scrollable}

::: {.panel-tabset}

### Slide 

- A simple use-case with only [**2 variables**]{.orange}:
  - [**Textual description**]{.blue2} of the activity – [text]{.green2}
  - [**True NACE code**]{.blue2} labelised by the rule-based engine – [nace]{.green2} (732 modalities)

- Standard [**preprocessing**]{.orange}:
  - lowercasing
  - punctuation removal
  - number removal
  - stopwords removal
  - stemming
  - ...


### Raw

```{ojs}
viewof table_data = Inputs.table(transpose(data_raw), {
    rows: 22
})
```

### Preprocessed

```{ojs}
viewof table_data_prepro = Inputs.table(transpose(data_prepro), {
    rows: 22
})
```

:::

## MLflow with a non standard framework

::: {.nonincremental}

:::: {.fragment fragment-index=1}
- [**Easy to use**]{.orange} with a variety of machine learning frameworks (scikit-learn, Keras, Pytorch...) 
::::

:::: {.fragment fragment-index=2}
```python
mlflow.sklearn.log_model(pipe_rf, "model")

mlflow.pyfunc.load_model(model_uri=f"models:/{model_name}/{version}")
y_train_pred = model.predict(X_train)

```
::::

:::: {.fragment fragment-index=3}
- What if we require greater [**flexibility**]{.orange}, e.g. to use a [**custom framework**]{.orange}?
::::

:::: {.fragment fragment-index=4}
- Possibility to [**track**]{.orange} , [**register**]{.orange} and [**deliver**]{.orange} your own model
::::

:::

## MLflow with a non standard framework 

::: {.nonincremental}

:::: {.fragment fragment-index=1}
- There are [**2 main differences**]{.orange} when using your own framework:
  - [**logging**]{.blue2} of parameters, metrics and artifacts
  - [**wrapping**]{.blue2} of your custom model so that MLflow can serve it
::::

:::: {.fragment fragment-index=2}
```python
# Define a custom model
class MyModel(mlflow.pyfunc.PythonModel):

    def load_context(self, context):
      self.my_model.load_model(context.artifacts["my_model"])

    def predict(self, context, model_input):
        return self.my_model.predict(model_input)
```
::::

:::

<!-- By creating a class that inherits from mlflow.pyfunc.PythonModel, you are essentially creating a wrapper around your custom model that allows it to be used with the MLflow platform. The mlflow.pyfunc.PythonModel class provides a standardized interface that makes it easy to integrate your custom model with the rest of the MLflow platform. -->

## From experiment towards production

- Notebooks are not suitable to build [**production-grade**]{.orange} ML systems:
  - Limited potential for [**automation**]{.blue2} of ML pipelines.
  - Lack of clear and [**reproducible**]{.blue2} workflows.
  - Hinders [**collaboration**]{.blue2} and [**versioning**]{.blue2} among team members.
  - Insufficient [**modularity**]{.blue2} for managing complex ML components.


```{python}
#| cache: false
import sys
sys.path.append("../src/")

import pandas as pd
import s3fs
import pyarrow.parquet as pq
from constants import TEXT_FEATURE, DATA_PATH
from preprocessor import Preprocessor

preprocessor = Preprocessor()
fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},key ='B1KYAWN1SN1PUWWG5GU1', secret = 'MogLaIumeXBqI6mBpxpLpQAzhYQ1tr3IgWQi3sTU', token = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.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.sARzICwGPHNu3TLCx4JXlK1dEq6I1fxKIRNhN8c8hAawzTVZ0qJjaPIao-M8lTMP7eFT6jK8czlD2qTZtexRbA')
df = pq.ParquetDataset(DATA_PATH, filesystem=fs).read_pandas().to_pandas()
df = df.sample(frac=0.001, random_state=0)

df_prepro = preprocessor.clean_text(df, TEXT_FEATURE)

ojs_define(data_raw = df, data_prepro = df_prepro)
```
