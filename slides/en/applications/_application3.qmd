
::::{.callout-tip collapse="true" icon=false}
## Part 1: Exposing a ML model locally as an API

:::::{.nonincremental}

1. We constructed a very simplistic Rest API using FastAPI. All underlying files are in the `app` folder. Check them.
2. Deploy the API locally by running the following commands in a terminal:

```shell
export MLFLOW_MODEL_NAME="fasttext"
export MLFLOW_MODEL_VERSION=1
uvicorn app.main:app --root-path /proxy/8000
```

3. Open the API page using the button provided by `VSCode`.
4. Display your API documentation by adding `/docs` to your URL.
5. Test your API!

:::::
::::

## Application 3 {.scrollable}

::::{.callout-tip collapse="true" icon=false}
## Part 2 : Deploying manually a machine-learning model as an API

:::::{.nonincremental}

0. Open the `Dockerfile` to see how the image is built. The image is automatically rebuilt and published via Github Actions, if interested have a look to `.github/workflows/build_image.yml`. Dans le cadre de cette formation, nous allons tous utiliser cette même image.
1. Open the file `kubernetes/deployment.yml` and modify the highlighted lines accordingly:

```{.yml code-line-numbers="7,9,11" filename="deployment.yml"}
containers:
- name: api
    image: inseefrlab/formation-mlops-api:main
    imagePullPolicy: Always
    env:
    - name: MLFLOW_TRACKING_URI
        value: https://user-<namespace>-<pod_id>.user.lab.sspcloud.fr
    - name: MLFLOW_MODEL_NAME
        value: fasttext
    - name: MLFLOW_MODEL_VERSION
        value: "1"
```


2. Open the file `kubernetes/ingress.yml` and modify (two times) the URL of the API endpoint to be of the form `<your_firstname>-<your_lastname>-api.lab.sspcloud.fr`
3. Apply the three `Kubernetes` contracts contained in the `kubernetes/` folder in a terminal to deploy the API

```shell
kubectl apply -f formation-mlops/kubernetes/
```

4. Reach your API using the URL defined in your `ingress.yml` file
5. Re-train a new model and deploy this new model in your API

<details>
<summary>
    <font size=\"3\" color=\"darkgreen\"><b>Cliquez pour voir les étapes </b></font>
</summary>

1. Train a model
2. Register the model in MLflow
3. Adjust your `MLFLOW_MODEL_NAME` or `MLFLOW_MODEL_VERSION` (if you didn't modify the model name) environment variable in the `deployment.yml` file
4. Apply the new `Kubernetes` contracts to update the API

```shell
kubectl apply -f formation-mlops/kubernetes/
```

6. Refresh your API, and verify on the home page that it is now based on the new version of the model

</details>

:::::
::::

## Application 3 {.scrollable}

::::{.callout-tip collapse="true" icon=false}
## Part 3 : déploiement continu d'un modèle de ML en tant qu'API

:::::{.nonincremental}

⚠️ The previous applications must have been created with the Git option to be able to follow this one.

Previously, you deployed your model manually. Thanks to `ArgoCD`, it is possible to deploy a model continuously. This means that every modification of a file in the `kubernetes/` folder will automatically trigger redeployment, synchronized with your GitHub repository. To convince yourself, follow the steps below:

0. Delete the manual deployment of the previous application to prevent Kubernetes resources from overlapping:

```shell
kubectl delete -f formation-mlops/kubernetes/
```

1. Launch an `ArgoCD` service by clicking on this [URL](https://datalab.sspcloud.fr/launcher/automation/argo-cd?version=0.5.3&autoLaunch=true). Open the service, enter the username (`admin`), and the service's password.
2. Commit the changes made and push them to your GitHub repository.
3. Open the template `argocd/template-argocd.yml` and modify the highlighted lines:

```{.yml code-line-numbers="4,9" filename="template-argocd.yml"}
spec:
  project: default
  source:
    repoURL: https://github.com/<your-github-id>/formation-mlops.git
    targetRevision: HEAD
    path: kubernetes
  destination:
    server: https://kubernetes.default.svc
    namespace: <your-namespace>
```

4. In ArgoCD, click on `New App` and then `Edit as a YAML`. Copy and paste the content of `argocd/template-argocd.yml`, and click on `Create`.
5. Reach your API using the URL defined in your `ingress.yml` file
6. Display the documentation of your API by adding `/docs` to your URL
7. Try your API out!
8. Re-train a new model and deploy **automatically** this new model in your API

<details>
<summary>
    <font size=\"3\" color=\"darkgreen\"><b>Click to see the steps </b></font>
</summary>

1. Train a model
2. Register the model in MLflow
3. Adjust your `MLFLOW_MODEL_NAME` or `MLFLOW_MODEL_VERSION` (if you didn't modify the model name) environment variable in the `deployment.yml` file
4. Commit these changes and push them to your GitHub repository.
5. Wait for 5 minutes for `ArgoCD` to automatically synchronize the changes from your GitHub repository, or force synchronization. Refresh your API and check on the homepage that it is now based on the new version of the model.

</details>

:::::
::::


## Application 3 {.scrollable}

::::{.callout-tip collapse="true" icon=false}
## Part 4: Querying your deployed model

:::::{.nonincremental}

1. Create a file `predict_api.py`. This script should:
    - Read the parquet file available at the following address:

    ```shell
    https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet
    ``` 

    - Make queries to your API for each label present in the parquet file.
    - Display the prediction results.

<details> 
<summary> 
    <font size=\"3\" color=\"darkgreen\"><b>Click to see the script content </b></font>
</summary>

```{.python filename="predict_api.py"}
import pandas as pd
import requests


# Function to make a request to the API
def make_prediction(api_url: str, description: str):
    params = {"description": description, "nb_echoes_max": 2}
    response = requests.get(api_url, params=params)
    return response.json()


# Data URL
data_path = "https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet"

# Load the Parquet file into a pandas DataFrame
df = pd.read_parquet(data_path)

# API URL
api_url = "https://<your_firstname>-<your_lastname>-api.lab.sspcloud.fr/predict"

# Make the requests
responses = df["text"].apply(lambda x: make_prediction(api_url, x))

# Display the DataFrame with prediction results
print(pd.merge(df, pd.json_normalize(responses),
               left_index=True,
               right_index=True))

```
</details>

2. Run your `predict_api.py` script.

<details> 
<summary> 
    <font size=\"3\" color=\"darkgreen\"><b>Click to see the command </b></font> 
</summary>

```shell
python formation-mlops/src/predict_api.py
```
</details>

3. In ArgoCD, open your application and click on your pod that should start with `"codification-api-..."`.  Observe the logs.

4. What information do you have? Is it sufficient?

::::

:::: {.callout-important collapse="true"}

We performed a series of GET requests here as we have a single entry point to our API. To perform batch queries, it is preferable to use POST requests.

::::
:::
