## Mise en service du modèle

- Une fois qu'un modèle de machine learning a été développé, il doit être [**déployé**]{.orange} pour [**servir**]{.orange} ses utilisateurs finaux.
  - Quelle est l'infrastructure de [**production**]{.blue2} ?
  - Qui sont les [**utilisateurs finaux**]{.blue2} ?
  - [**Traitement par lots**]{.blue2} (*batch*) par rapport au [**traitement en ligne**]{.blue2} (*online*)

## Configuration standard

- Infrastructure de production : cluster [**Kubernetes**]{.orange}

- Le modèle peut servir [**diverses applications**]{.orange}
  - Rendre le modèle accessible via une [**API**]{.blue2}

- [**Traitement en ligne**]{.orange} (*online serving*)
  - Les applications [**client**]{.blue2} envoient une [**requête**]{.blue2} à l'API et reçoivent une [**réponse**]{.blue2} rapide

## Exposer un modèle via une API

![](../img/API.png){fig-align="center"}

## Exécuter une API dans un conteneur

- [**Conteneur**]{.orange} : environnement [**autonome**]{.blue2} et [**isolé**]{.blue2} qui encapsule le modèle, ses dépendances et le code de l'API

- Les conteneurs offrent une grande [**portabilité**]{.orange} et [**scalabilité**]{.orange} pour distribuer le modèle de manière efficace.

- Le fichier `Dockerfile` est utilisé pour configurer et construire le conteneur Docker.

## Développement avec l'architecture Docker

![](../img/docker-workflow.png){fig-align="center" width="87%"}

::: aside
Source: [R. Krispin](https://github.com/RamiKrispin/vscode-python)
:::

## Déploiement d'une API sur `Kubernetes`
<!-- - Need a [**container orchestration tool**]{.orange} such as kubernetes -->
- [**3 fichiers principaux**]{.orange} sont nécessaires pour déployer une API :
  - `deployment.yaml` : définit le fonctionnement de l'API (image du conteneur, ressources et variables d'environnement)
  - `service.yaml` : établit un point de terminaison réseau [**interne**]{.blue2} stable pour l'API.
  - `ingress.yaml` : fournit un point d'entrée pour les clients [**externes**]{.blue2} afin d'accéder à l'API.
