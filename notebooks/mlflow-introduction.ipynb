{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d546b38-f8b7-438d-9808-abfa3c61c993",
   "metadata": {},
   "source": [
    "# Tutorial : introduction to MLFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91d0f60f-e70f-41f4-99ed-1e9800cfa9f7",
   "metadata": {},
   "source": [
    "This first application introduces the basic concepts of `MLFlow`. The goal is to predict the income class of individuals using a sample data from the US Census and a Random Forest classifier using the popular [scikit-learn](https://scikit-learn.org/stable/) machine learning `Python` library. \n",
    "\n",
    "We first illustrate how we would perform the training and fine-tuning of the model in a traditional way. Then, we show how we can integrate it as an **MLflow experiment**, so as to **log** relevant parameters and metrics in `MLflow`'s **tracking server** and visualize them in the UI. Finally, we illustrate how selected models can transition from the tracking server to the **model registry**, and how they can then be used from there to perform inference on new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2ed5cf-810d-47ea-ade3-f92f5e3771be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba85244-30af-43f4-92f2-a15bf67cf16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b67a65-102f-4069-8cc8-4c64dcdc00ec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed086e6",
   "metadata": {},
   "source": [
    "For this application, we'll use a classical dataset extracted from the 1994 US Census bureau data. The goal is to determine whether a person makes over $50K a year ('>50K') or less ('<=50K') using sociodemographic characteristics on the selected individuals. As the available variables are generally self-explanatory, we won't describe the data much, but more information on them can be found in the original [Kaggle challenge](https://www.kaggle.com/datasets/uciml/adult-census-income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24ae610-bb74-405b-9df0-06d423fd03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/adult-census-us.csv\"\n",
    "df_census = pd.read_csv(url_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322565d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num   \n",
       "0    2         State-gov   77516  Bachelors             13  \\\n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex   \n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male  \\\n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1291ee38",
   "metadata": {},
   "source": [
    "The goal is to predict the income class, so we must first set it aside from the training data. As this variable consists in string-encoded categories, we must encode it in a numerical format to be able to feed it to a machine learning model. A common practice for ordinal data (data for which an order exists, such as income class) is to encode labels as subsequent integers starting at 0, a technique known as **label encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30313ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X = df_census.drop(columns=\"class\")\n",
    "y = le.fit_transform(df_census[\"class\"].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c770dee4",
   "metadata": {},
   "source": [
    "These new integer-encoded categories can naturally be mapped to the original values of the variable, and conversely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fe46f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The encoded classes\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c732d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "['<=50K' '<=50K' '<=50K' ... '<=50K' '<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# The corresponding original classes\n",
    "print(y)\n",
    "print(np.array([le.classes_[i] for i in y]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb4f2f3e",
   "metadata": {},
   "source": [
    "A common practice in machine learning projects is to start by setting a fraction of the data aside as a **test dataset**. This data will be used at the very end of the project in order to properly evaluate the generalization performance of our selected algorithm, i.e. how it would perform on new unseen data. The rest of the data (**training dataset**) will be used to train the algorithms and compare their performance. Without this step, we are at risk of overfitting our models on the available data so that our evaluation metrics would no longer properly estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fded59-b6f4-4647-809b-643bef3b056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c259a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39073 entries, 22729 to 2732\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             39073 non-null  int64 \n",
      " 1   workclass       36830 non-null  object\n",
      " 2   fnlwgt          39073 non-null  int64 \n",
      " 3   education       39073 non-null  object\n",
      " 4   education-num   39073 non-null  int64 \n",
      " 5   marital-status  39073 non-null  object\n",
      " 6   occupation      36821 non-null  object\n",
      " 7   relationship    39073 non-null  object\n",
      " 8   race            39073 non-null  object\n",
      " 9   sex             39073 non-null  object\n",
      " 10  capitalgain     39073 non-null  int64 \n",
      " 11  capitalloss     39073 non-null  int64 \n",
      " 12  hoursperweek    39073 non-null  int64 \n",
      " 13  native-country  38404 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab462d9",
   "metadata": {},
   "source": [
    "These general information show that thousands of observations are missing for some variables. To avoid wasting data and since these might not be missing-at-random, we'll impute values for the missing ones :\n",
    "- for numerical variables, we'll impute the median of the variable\n",
    "- for categorical variables, we'll impute the mode, i.e. the most frequent category in the data\n",
    "\n",
    "As previously, string-encoded categorical variables must also be converted to some form of numerical data. We'll use the same encoding strategy as the one used to encode the target variable.\n",
    "\n",
    "So as to make all these steps as reproducible as possible, we formalize them as a `scikit-learn` `Pipeline` object. More information on their justification and the way there are used can be found in the [documentation](https://scikit-learn.org/stable/modules/compose.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0135c24-826e-47e3-931c-7db4ec20b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "categorical_transformer = make_pipeline(mode_imputer, ordinal_encoder)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", median_imputer, make_column_selector(dtype_include=np.int64)),\n",
    "        (\"categorical\", categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ab4ca8",
   "metadata": {},
   "source": [
    "As most `scikit-learn` objects, the pipeline must first `fit` the data (e.g. compute the most frequent value or median). Then, we can use it to `transform` the data. The resulting object is a `NumPy` array with the same structure as the original data. It is not very useful per se, but it shows us that the categorical variables are indeed transformed into numerical values. This numerical array can then be fed to a machine learning model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58964862-1e9f-4fca-b158-4891057db7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.17372e+05, 7.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [2.00000e+00, 3.57720e+05, 1.10000e+01, ..., 4.00000e+00,\n",
       "        0.00000e+00, 3.80000e+01],\n",
       "       [4.00000e+00, 2.02242e+05, 9.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       ...,\n",
       "       [2.00000e+00, 3.44624e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [3.00000e+00, 1.04489e+05, 1.30000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [0.00000e+00, 1.86925e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81610-0b95-4dcd-96b0-ec2eebbc7281",
   "metadata": {},
   "source": [
    "## Training models : the classical way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "506fd5be",
   "metadata": {},
   "source": [
    "In order to really understand why the MLOps approach is desirable, we must first get an idea of how we would train our model without it, i.e. the \"classical\" way. The workflow we are trying to achieve is best described by the following figure from the [scikit-learn documentation](https://scikit-learn.org/stable/).\n",
    "\n",
    "![](img/grid_search_workflow.png){fig-align=\"center\" height=300}\n",
    "\n",
    "Using the training data, we want to train a model so as to get the best generalization performance, i.e. minimize the prediction error on unseen data. To do so, we have to **fine-tune** the **hyperparameters** of our model, i.e. find the combination of **hyperparameters** that provide the best performance. In order to avoid **overfitting** when doing so, we use a procedure called **cross-validation** (described in details [here](https://scikit-learn.org/stable/modules/cross_validation.html)). When we have found the optimal set of hyperparameters, we use the model train with those for a final evaluation on the test set.\n",
    "\n",
    "In this example, we train a *Random Forest* to discriminate the two income classes. First, we build a `Pipeline` object that integrates the preprocessing step as well as the model, so as to be able to improve reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef674c48-5111-40af-81d4-02c0ec18ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classifier', rf_clf)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a39f87d5",
   "metadata": {},
   "source": [
    "Although the hyperparameters provided natively by `scikit-learn` are usually good defaults, we will of course want to check whether we can improve the performance further by **fine-tuning** the relevant hyperparameters. To do so, we use the *grid search* method, which amounts to testing all the possible hyperparameters combinations along given values (*grid*) for these hyperparameters. For each combination, a performance evaluation is performed using a 5-folds *cross-validation*. As the accuracy is rarely a relevant metric for classification problems because of class imbalance, we also request the precision, the recall and the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819fa1df-292f-4c3d-b9af-c2e164f391a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_leaf_nodes\": [5, 10, 50]\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rf, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "                         refit=\"f1\",\n",
    "                         cv=5, \n",
    "                         n_jobs=5, \n",
    "                         verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b74c3f16",
   "metadata": {},
   "source": [
    "**Exercise** : can you guess the total number of `fit` steps that will be performed when calling the `fit` method on the `pipe_gscv` object ?\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Cliquez pour affichez la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "From the grid search only, there are 3 * 3 = 9 candidate models to train. However, for each combination, a 5-folds cross-validation is performed, which involves 5 training steps (*fits*). So altogether, there will be 9 * 5 = 45 *fits* to compute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd56281e-31dc-4a24-940e-6eb180aad8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ordinalencoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0&gt;)])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310&gt;),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinalencoder&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('numerical',\n",
       "                                                                         SimpleImputer(strategy='median'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f9afaf40310>),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f9afafa17e0>)])),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'classifier__max_leaf_nodes': [5, 10, 50],\n",
       "                         'classifier__n_estimators': [50, 100, 200]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f217e9ab",
   "metadata": {},
   "source": [
    "We can get detailed results for each candidate model in a `Pandas DataFrame`. This enables us to compare the models and select the best candidate based on their respective performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4541f8d2-7fac-4407-928d-b70c3640fa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__max_leaf_nodes</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523778</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.051566</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.827639</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.832118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>7</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.543811</td>\n",
       "      <td>0.557421</td>\n",
       "      <td>0.528157</td>\n",
       "      <td>0.543469</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928245</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.086699</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.825080</td>\n",
       "      <td>0.831734</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>8</td>\n",
       "      <td>0.514732</td>\n",
       "      <td>0.536809</td>\n",
       "      <td>0.523557</td>\n",
       "      <td>0.530239</td>\n",
       "      <td>0.517448</td>\n",
       "      <td>0.524557</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.728486</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.128356</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.825848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>9</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.514449</td>\n",
       "      <td>0.513224</td>\n",
       "      <td>0.512221</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580412</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.055708</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>0.841331</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567763</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>0.590894</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.583145</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.058457</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.084588</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831094</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.837236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.591401</td>\n",
       "      <td>0.587281</td>\n",
       "      <td>0.575057</td>\n",
       "      <td>0.577098</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n",
       "0       0.523778      0.007825         0.051566        0.001610  \\\n",
       "1       0.928245      0.006751         0.086699        0.002097   \n",
       "2       1.728486      0.019958         0.128356        0.002594   \n",
       "3       0.580412      0.003979         0.055708        0.002100   \n",
       "4       1.058457      0.017652         0.084588        0.001202   \n",
       "\n",
       "  param_classifier__max_leaf_nodes param_classifier__n_estimators   \n",
       "0                                5                             50  \\\n",
       "1                                5                            100   \n",
       "2                                5                            200   \n",
       "3                               10                             50   \n",
       "4                               10                            100   \n",
       "\n",
       "                                              params  split0_test_accuracy   \n",
       "0  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.827639  \\\n",
       "1  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.825080   \n",
       "2  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.823800   \n",
       "3  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831862   \n",
       "4  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831094   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_recall   \n",
       "0              0.833781              0.832118  ...         0.013073  \\\n",
       "1              0.831734              0.827895  ...         0.007155   \n",
       "2              0.828279              0.825848  ...         0.005810   \n",
       "3              0.841331              0.837876  ...         0.010626   \n",
       "4              0.840691              0.837236  ...         0.009021   \n",
       "\n",
       "   rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1   \n",
       "0                 7        0.541993        0.545963        0.543811  \\\n",
       "1                 8        0.514732        0.536809        0.523557   \n",
       "2                 9        0.503067        0.520714        0.514449   \n",
       "3                 4        0.567763        0.595828        0.590894   \n",
       "4                 5        0.564931        0.591401        0.587281   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.557421        0.528157      0.543469     0.009356             7  \n",
       "1        0.530239        0.517448      0.524557     0.008130             8  \n",
       "2        0.513224        0.512221      0.512735     0.005667             9  \n",
       "3        0.574122        0.583145      0.582351     0.010351             4  \n",
       "4        0.575057        0.577098      0.579154     0.009374             5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_results = pd.DataFrame(pipe_gscv.cv_results_)\n",
    "gscv_results.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb75b873",
   "metadata": {},
   "source": [
    "The fitted `Pipeline` object actually keep tracks of the best model for us. We can thus show the best performing set of hyperparameters, and use the model trained with these hyperparameters to compute the final score on the test set (not used until yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23990354-0989-454f-a1d3-c2f230d82d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_leaf_nodes': 50, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_gscv.best_params_)\n",
    "\n",
    "best_model = pipe_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1042c22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.646433990895296\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6e06080",
   "metadata": {},
   "source": [
    "In order for this analysis to be reproducible, we must find a way to export the results. Fortunately, `scikit-learn` models are serializable. One way to persist them is to use `joblib` (see the [documentation on model persistence](https://scikit-learn.org/stable/model_persistence.html) for a more detailed discussion on possible way to export models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca46c05-9f19-4269-9311-ccb547d40ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pipeline_train_model_20230118.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"models/\"):\n",
    "    os.makedirs(\"models/\")\n",
    "joblib.dump(pipe_gscv, 'models/pipeline_train_model_20230118.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f985c76",
   "metadata": {},
   "source": [
    "This is convenient for the development phase, but it is also very clear that **this way of persisting models is not production-grade nor scalable** :\n",
    "- first and foremost, we lack a proper way to **track experiments** (data used for training, environment configuration, metrics...)\n",
    "- only one model (the best one) is persisted, whereas we could want to keep the other ones as artifacts for exploration or validation purpose\n",
    "- we can parallelize the cross-validation computation, but we can't readily parallelize the evaluation of each hyperparameters combination\n",
    "- there is no easy way to distribute the serialized models, so the collaboration of several team members on a given experiment is complicated \n",
    "\n",
    "The MLOps principles were precisely devised to solve these various problems. Let's see now how MLflow enables us to implement them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc5b57-6dcc-4bf1-a2c3-29ae13300e46",
   "metadata": {},
   "source": [
    "## Training models : the MLFlow way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b194e-cbdf-463a-a7fd-e71ce0ddae19",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04c359c4",
   "metadata": {},
   "source": [
    "The main component of `MLflow` is the *Tracking Server*, which tracks experiments and save the relevant data and metadata. More precisely, for each *run* (\"execution of some piece of data science code\"), the *Tracking Server* records : \n",
    "- **experiments data** (parameters, metrics, tags, notes, metadata, ...) in a **backend store** (in our case, a `PostgreSQL` database)\n",
    "- **artifacts** (models, files, images, ...) in an **artifact store** (in our case, `S3`-like storage)\n",
    "\n",
    "As a user, we communicate with the *Tracking Server* through a client (in our case, a `Jupyter` notebook with a `Python` kernel).\n",
    "\n",
    "Fortunately, in a properly set up environment, these three communication levels can be pre-configured so that they are relatively transparent to the user. This enables the data scientist to focus on the business task at hand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1c0dc8f",
   "metadata": {},
   "source": [
    "![](img/mlflow-tracking.png){fig-align=\"center\" height=400}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a155b49",
   "metadata": {},
   "source": [
    "The client must know the URI of the *tracking server*. If a `MLflow` instance has been launched on the SSP Cloud previous to the client, the client will automatically discover the URI. If not, it must be set manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91a2e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow was not automatically discovered, a tracking URI must be provided manually.\n"
     ]
    }
   ],
   "source": [
    "# Automatic discovery : if MLFlow has been launched before Jupyter/VSCode\n",
    "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
    "    print(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "else:\n",
    "    print(\"MLflow was not automatically discovered, a tracking URI must be provided manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15061562-8b91-45c4-8ada-f8458873e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual configuration : if MLFlow has been launched after Jupyter/VSCode\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"copy_uri_from_mlflow_service_README_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b55dd7-1f2c-42fa-941d-bad8412cdd16",
   "metadata": {},
   "source": [
    "### Training and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c322c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e725454b-6be2-4e04-8bbd-444608eedb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_mlflow_tracking(mlflow_experiment_name,\n",
    "                                     n_estimators,\n",
    "                                     max_leaf_nodes):\n",
    "    # Set up MLFlow context\n",
    "    mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Training step\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                        max_leaf_nodes=max_leaf_nodes,\n",
    "                                        random_state=SEED)\n",
    "        pipe_rf = Pipeline([\n",
    "            ('preprocessor', preprocessor), \n",
    "            ('classifier', rf_clf)\n",
    "        ])\n",
    "        y_train_pred = cross_val_predict(estimator=pipe_rf, \n",
    "                                         X=X_train, \n",
    "                                         y=y_train,\n",
    "                                         cv=5, \n",
    "                                         n_jobs=5, \n",
    "                                         verbose=1)\n",
    "        \n",
    "        # Compute fit metrics\n",
    "        accuracy = accuracy_score(y_train_pred, y_train)\n",
    "        precision = precision_score(y_train_pred, y_train)\n",
    "        recall = recall_score(y_train_pred, y_train)\n",
    "        f1 = f1_score(y_train_pred, y_train)\n",
    "        \n",
    "        # Track training data\n",
    "        mlflow.log_param(\"data_url\", url_data)\n",
    "        \n",
    "        # Track hyperparameters\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_leaf_nodes\", max_leaf_nodes)\n",
    "        \n",
    "        # Track fit metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        # Track model binary\n",
    "        mlflow.sklearn.log_model(pipe_rf, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b418de38-8a86-4b0a-9dc9-4d7f49302972",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model_with_mlflow_tracking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m n_estimator \u001b[39min\u001b[39;00m n_estimators_range:\n\u001b[1;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m max_leaf_nodes \u001b[39min\u001b[39;00m max_leaf_nodes_range:\n\u001b[0;32m----> 7\u001b[0m         train_model_with_mlflow_tracking(\n\u001b[1;32m      8\u001b[0m             mlflow_experiment_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtutorial-mlflow\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             n_estimators\u001b[39m=\u001b[39mn_estimator,\n\u001b[1;32m     10\u001b[0m             max_leaf_nodes\u001b[39m=\u001b[39mmax_leaf_nodes\n\u001b[1;32m     11\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model_with_mlflow_tracking' is not defined"
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "n_estimators_range = [50, 100, 200]\n",
    "max_leaf_nodes_range = [5, 10, 50]\n",
    "\n",
    "for n_estimator in n_estimators_range:\n",
    "    for max_leaf_nodes in max_leaf_nodes_range:\n",
    "        train_model_with_mlflow_tracking(\n",
    "            mlflow_experiment_name=\"tutorial-mlflow\",\n",
    "            n_estimators=n_estimator,\n",
    "            max_leaf_nodes=max_leaf_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e20f4-139c-4ac2-9c83-430552619ca4",
   "metadata": {},
   "source": [
    "### Using the model registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39735-cd52-46bb-9559-81c6f393b3c5",
   "metadata": {},
   "source": [
    "Ajouter un premier modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0acf4dea-c4fa-434f-998a-64ce0b7da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_pred, y):\n",
    "    accuracy = accuracy_score(y_train_pred, y_train)\n",
    "    f1 = f1_score(y_train_pred, y_train)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    accuracy : {accuracy}\n",
    "    f1_score : {f1}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b7520d8-8e7c-418e-acb6-5daac6ecc2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:28:30 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8513551557341387\n",
      "    f1_score : 0.6448575272104684\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "version = 1\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{version}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c524-669f-4cc7-bb15-4a7494c0949e",
   "metadata": {},
   "source": [
    "Tagguer le modèle en prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e88bc7-d1c9-497b-8b02-debcca25a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:20 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8513551557341387\n",
      "    f1_score : 0.6448575272104684\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a7210-bf68-4785-b3e6-e21ce2333e61",
   "metadata": {},
   "source": [
    "Ajouter un second modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca23e4e6-29c7-4a17-ae68-2c25e2d78382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:23 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8514831213369847\n",
      "    f1_score : 0.6433970380384686\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "version = 2\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{version}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d553b-3309-4e51-af30-878c785f102b",
   "metadata": {},
   "source": [
    "Tagguer le nouveau modèle en staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f16f6497-ebfd-4eb7-9ee4-e5191f9763d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:25 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8514831213369847\n",
      "    f1_score : 0.6433970380384686\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "stage = 'Staging'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209af40-cb49-4b75-b9ca-9a9b9de4c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
