{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d546b38-f8b7-438d-9808-abfa3c61c993",
   "metadata": {},
   "source": [
    "# Tutorial : introduction to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0f60f-e70f-41f4-99ed-1e9800cfa9f7",
   "metadata": {},
   "source": [
    "This first application introduces the basic concepts of `MLFlow`. The goal is to predict the income class of individuals using a sample data from the US Census and a Random Forest classifier using the popular [scikit-learn](https://scikit-learn.org/stable/) machine learning `Python` library. \n",
    "\n",
    "We first illustrate how we would perform the training and fine-tuning of the model in a traditional way. Then, we show how we can integrate it as an **MLflow experiment**, so as to **log** relevant parameters and metrics in `MLflow`'s **tracking server** and visualize them in the UI. Finally, we illustrate how selected models can transition from the tracking server to the **model registry**, and how they can then be used from there to perform inference on new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca2ed5cf-810d-47ea-ade3-f92f5e3771be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ba85244-30af-43f4-92f2-a15bf67cf16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b67a65-102f-4069-8cc8-4c64dcdc00ec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed086e6",
   "metadata": {},
   "source": [
    "For this application, we'll use a classical dataset extracted from the 1994 US Census bureau data. The goal is to determine whether a person makes over $50K a year ('>50K') or less ('<=50K') using sociodemographic characteristics on the selected individuals. As the available variables are generally self-explanatory, we won't describe the data much, but more information on them can be found in the original [Kaggle challenge](https://www.kaggle.com/datasets/uciml/adult-census-income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e24ae610-bb74-405b-9df0-06d423fd03c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/adult-census-us.csv\"\n",
    "df_census = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "322565d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num   \n",
       "0    2         State-gov   77516  Bachelors             13  \\\n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex   \n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male  \\\n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291ee38",
   "metadata": {},
   "source": [
    "The goal is to predict the income class, so we must first set it aside from the training data. As this variable consists in string-encoded categories, we must encode it in a numerical format to be able to feed it to a machine learning model. A common practice for ordinal data (data for which an order exists, such as income class) is to encode labels as subsequent integers starting at 0, a technique known as **label encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f30313ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X = df_census.drop(columns=\"class\")\n",
    "y = le.fit_transform(df_census[\"class\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770dee4",
   "metadata": {},
   "source": [
    "These new integer-encoded categories can naturally be mapped to the original values of the variable, and conversely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07fe46f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The encoded classes\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c732d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "['<=50K' '<=50K' '<=50K' ... '<=50K' '<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# The corresponding original classes\n",
    "print(y)\n",
    "print(np.array([le.classes_[i] for i in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f2f3e",
   "metadata": {},
   "source": [
    "A common practice in machine learning projects is to start by setting a fraction of the data aside as a **test dataset**. This data will be used at the very end of the project in order to properly evaluate the generalization performance of our selected algorithm, i.e. how it would perform on new unseen data. The rest of the data (**training dataset**) will be used to train the algorithms and compare their performance. Without this step, we are at risk of overfitting our models on the available data so that our evaluation metrics would no longer properly estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89fded59-b6f4-4647-809b-643bef3b056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c259a228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39073 entries, 22729 to 2732\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             39073 non-null  int64 \n",
      " 1   workclass       36830 non-null  object\n",
      " 2   fnlwgt          39073 non-null  int64 \n",
      " 3   education       39073 non-null  object\n",
      " 4   education-num   39073 non-null  int64 \n",
      " 5   marital-status  39073 non-null  object\n",
      " 6   occupation      36821 non-null  object\n",
      " 7   relationship    39073 non-null  object\n",
      " 8   race            39073 non-null  object\n",
      " 9   sex             39073 non-null  object\n",
      " 10  capitalgain     39073 non-null  int64 \n",
      " 11  capitalloss     39073 non-null  int64 \n",
      " 12  hoursperweek    39073 non-null  int64 \n",
      " 13  native-country  38404 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab462d9",
   "metadata": {},
   "source": [
    "These general information show that thousands of observations are missing for some variables. To avoid wasting data and since these might not be missing-at-random, we'll impute values for the missing ones :\n",
    "- for numerical variables, we'll impute the median of the variable\n",
    "- for categorical variables, we'll impute the mode, i.e. the most frequent category in the data\n",
    "\n",
    "As previously, string-encoded categorical variables must also be converted to some form of numerical data. We'll use the same encoding strategy as the one used to encode the target variable.\n",
    "\n",
    "So as to make all these steps as reproducible as possible, we formalize them as a `scikit-learn` `Pipeline` object. More information on their justification and the way there are used can be found in the [documentation](https://scikit-learn.org/stable/modules/compose.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0135c24-826e-47e3-931c-7db4ec20b9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "categorical_transformer = make_pipeline(mode_imputer, ordinal_encoder)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", median_imputer, make_column_selector(dtype_include=np.int64)),\n",
    "        (\"categorical\", categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab4ca8",
   "metadata": {},
   "source": [
    "As most `scikit-learn` objects, the pipeline must first `fit` the data (e.g. compute the most frequent value or median). Then, we can use it to `transform` the data. The resulting object is a `NumPy` array with the same structure as the original data. It is not very useful per se, but it shows us that the categorical variables are indeed transformed into numerical values. This numerical array can then be fed to a machine learning model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58964862-1e9f-4fca-b158-4891057db7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.17372e+05, 7.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [2.00000e+00, 3.57720e+05, 1.10000e+01, ..., 4.00000e+00,\n",
       "        0.00000e+00, 3.80000e+01],\n",
       "       [4.00000e+00, 2.02242e+05, 9.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       ...,\n",
       "       [2.00000e+00, 3.44624e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [3.00000e+00, 1.04489e+05, 1.30000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [0.00000e+00, 1.86925e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81610-0b95-4dcd-96b0-ec2eebbc7281",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the classical way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fd5be",
   "metadata": {},
   "source": [
    "In order to really understand why the MLOps approach is desirable, we must first get an idea of how we would train our model without it, i.e. the \"classical\" way. The workflow we are trying to achieve is best described by the following figure from the [scikit-learn documentation](https://scikit-learn.org/stable/).\n",
    "\n",
    "<img src=\"img/grid_search_workflow.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using the training data, we want to train a model so as to get the best generalization performance, i.e. minimize the prediction error on unseen data. To do so, we have to **fine-tune** the **hyperparameters** of our model, i.e. find the combination of **hyperparameters** that provide the best performance. In order to avoid **overfitting** when doing so, we use a procedure called **cross-validation** (described in details [here](https://scikit-learn.org/stable/modules/cross_validation.html)). When we have found the optimal set of hyperparameters, we use the model train with those for a final evaluation on the test set.\n",
    "\n",
    "In this example, we train a *Random Forest* to discriminate the two income classes. First, we build a `Pipeline` object that integrates the preprocessing step as well as the model, so as to be able to improve reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef674c48-5111-40af-81d4-02c0ec18ad22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classifier', rf_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f87d5",
   "metadata": {},
   "source": [
    "Although the hyperparameters provided natively by `scikit-learn` are usually good defaults, we will of course want to check whether we can improve the performance further by **fine-tuning** the relevant hyperparameters. To do so, we use the *grid search* method, which amounts to testing all the possible hyperparameters combinations along given values (*grid*) for these hyperparameters. For each combination, a performance evaluation is performed using a 5-folds *cross-validation*. As the accuracy is rarely a relevant metric for classification problems because of class imbalance, we also request the precision, the recall and the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819fa1df-292f-4c3d-b9af-c2e164f391a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_leaf_nodes\": [5, 10, 50]\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rf, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "                         refit=\"f1\",\n",
    "                         cv=5, \n",
    "                         n_jobs=5, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3f16",
   "metadata": {},
   "source": [
    "**Exercise** : can you guess the total number of `fit` steps that will be performed when calling the `fit` method on the `pipe_gscv` object ?\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Cliquez pour affichez la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "From the grid search only, there are 3 * 3 = 9 candidate models to train. However, for each combination, a 5-folds cross-validation is performed, which involves 5 training steps (*fits*). So altogether, there will be 9 * 5 = 45 *fits* to compute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd56281e-31dc-4a24-940e-6eb180aad8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ordinalencoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0&gt;)])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0&gt;),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinalencoder&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('numerical',\n",
       "                                                                         SimpleImputer(strategy='median'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7feef03a71c0>),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7feeebc393f0>)])),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'classifier__max_leaf_nodes': [5, 10, 50],\n",
       "                         'classifier__n_estimators': [50, 100, 200]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217e9ab",
   "metadata": {},
   "source": [
    "We can get detailed results for each candidate model in a `Pandas DataFrame`. This enables us to compare the models and select the best candidate based on their respective performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4541f8d2-7fac-4407-928d-b70c3640fa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__max_leaf_nodes</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588553</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.827639</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.832118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>7</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.543811</td>\n",
       "      <td>0.557421</td>\n",
       "      <td>0.528157</td>\n",
       "      <td>0.543469</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.023803</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.825080</td>\n",
       "      <td>0.831734</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>8</td>\n",
       "      <td>0.514732</td>\n",
       "      <td>0.536809</td>\n",
       "      <td>0.523557</td>\n",
       "      <td>0.530239</td>\n",
       "      <td>0.517448</td>\n",
       "      <td>0.524557</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.937115</td>\n",
       "      <td>0.030574</td>\n",
       "      <td>0.125391</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.825848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>9</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.514449</td>\n",
       "      <td>0.513224</td>\n",
       "      <td>0.512221</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698170</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>0.841331</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567763</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>0.590894</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.583145</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.310193</td>\n",
       "      <td>0.048657</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831094</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.837236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.591401</td>\n",
       "      <td>0.587281</td>\n",
       "      <td>0.575057</td>\n",
       "      <td>0.577098</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n",
       "0       0.588553      0.007461         0.056585        0.000835  \\\n",
       "1       1.023803      0.026702         0.082221        0.002450   \n",
       "2       1.937115      0.030574         0.125391        0.001691   \n",
       "3       0.698170      0.024725         0.058852        0.001895   \n",
       "4       1.310193      0.048657         0.092042        0.003619   \n",
       "\n",
       "  param_classifier__max_leaf_nodes param_classifier__n_estimators   \n",
       "0                                5                             50  \\\n",
       "1                                5                            100   \n",
       "2                                5                            200   \n",
       "3                               10                             50   \n",
       "4                               10                            100   \n",
       "\n",
       "                                              params  split0_test_accuracy   \n",
       "0  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.827639  \\\n",
       "1  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.825080   \n",
       "2  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.823800   \n",
       "3  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831862   \n",
       "4  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831094   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_recall   \n",
       "0              0.833781              0.832118  ...         0.013073  \\\n",
       "1              0.831734              0.827895  ...         0.007155   \n",
       "2              0.828279              0.825848  ...         0.005810   \n",
       "3              0.841331              0.837876  ...         0.010626   \n",
       "4              0.840691              0.837236  ...         0.009021   \n",
       "\n",
       "   rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1   \n",
       "0                 7        0.541993        0.545963        0.543811  \\\n",
       "1                 8        0.514732        0.536809        0.523557   \n",
       "2                 9        0.503067        0.520714        0.514449   \n",
       "3                 4        0.567763        0.595828        0.590894   \n",
       "4                 5        0.564931        0.591401        0.587281   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.557421        0.528157      0.543469     0.009356             7  \n",
       "1        0.530239        0.517448      0.524557     0.008130             8  \n",
       "2        0.513224        0.512221      0.512735     0.005667             9  \n",
       "3        0.574122        0.583145      0.582351     0.010351             4  \n",
       "4        0.575057        0.577098      0.579154     0.009374             5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_results = pd.DataFrame(pipe_gscv.cv_results_)\n",
    "gscv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75b873",
   "metadata": {},
   "source": [
    "The fitted `Pipeline` object actually keep tracks of the best model for us. We can thus show the best performing set of hyperparameters, and use the model trained with these hyperparameters to compute the final score on the test set (not used until yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23990354-0989-454f-a1d3-c2f230d82d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_leaf_nodes': 50, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_gscv.best_params_)\n",
    "\n",
    "best_model = pipe_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1042c22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.646433990895296\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e06080",
   "metadata": {},
   "source": [
    "In order for this analysis to be reproducible, we must find a way to export the results. Fortunately, `scikit-learn` models are serializable. One way to persist them is to use `joblib` (see the [documentation on model persistence](https://scikit-learn.org/stable/model_persistence.html) for a more detailed discussion on possible way to export models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ca46c05-9f19-4269-9311-ccb547d40ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pipeline_train_model_20230118.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"models/\"):\n",
    "    os.makedirs(\"models/\")\n",
    "joblib.dump(pipe_gscv, 'models/pipeline_train_model_20230118.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f985c76",
   "metadata": {},
   "source": [
    "This is convenient for the development phase, but it is also very clear that **this way of persisting models is not production-grade nor scalable** :\n",
    "- first and foremost, we lack a proper way to **track experiments** (data used for training, environment configuration, metrics...)\n",
    "- we can not easily visualize the various metrics so as to compare and select the best model\n",
    "- we can parallelize the cross-validation computation, but we can't readily parallelize the evaluation of each hyperparameters combination\n",
    "- there is no easy and standardized way to distribute the serialized models, so the collaboration of several team members on a given experiment is complicated\n",
    "\n",
    "The MLOps principles were precisely devised to solve these various problems. Let's see now how MLflow enables us to implement them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc5b57-6dcc-4bf1-a2c3-29ae13300e46",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the MLFlow way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b194e-cbdf-463a-a7fd-e71ce0ddae19",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c359c4",
   "metadata": {},
   "source": [
    "The main component of `MLflow` is the *Tracking Server*, which tracks experiments and save the relevant data and metadata. More precisely, for each *run* (\"execution of some piece of data science code\"), the *Tracking Server* records : \n",
    "- **experiments data** (parameters, metrics, tags, notes, metadata, ...) in a **backend store** (in our case, a `PostgreSQL` database)\n",
    "- **artifacts** (models, files, images, ...) in an **artifact store** (in our case, `S3`-like storage)\n",
    "\n",
    "As a user, we communicate with the *Tracking Server* through a client (in our case, a `Jupyter` notebook with a `Python` kernel).\n",
    "\n",
    "Fortunately, in a properly set up environment, these three communication levels can be pre-configured so that they are relatively transparent to the user. This enables the data scientist to focus on the business task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0dc8f",
   "metadata": {},
   "source": [
    "<img src=\"img/mlflow-tracking.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155b49",
   "metadata": {},
   "source": [
    "The client must know the URI of the *tracking server*. If a `MLflow` instance has been launched on the SSP Cloud previous to the client, the client will automatically discover the URI. If not, it must be set manually. Opening this URL opens the UI of `MLflow`, which we will be using later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91a2e959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://user-avouacr-758617.user.lab.sspcloud.fr\n"
     ]
    }
   ],
   "source": [
    "# Automatic discovery : if MLFlow has been launched before Jupyter/VSCode\n",
    "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
    "    print(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "else:\n",
    "    print(\"MLflow was not automatically discovered, a tracking URI must be provided manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15061562-8b91-45c4-8ada-f8458873e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual configuration : if MLFlow has been launched after Jupyter/VSCode\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"copy_uri_from_mlflow_service_README_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b55dd7-1f2c-42fa-941d-bad8412cdd16",
   "metadata": {},
   "source": [
    "### Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa949cb-bf32-4ce7-9bfe-7b7dc3ec00df",
   "metadata": {},
   "source": [
    "In the previous steps, we fine-tuned our model, i.e. we trained the same model with several different combinations of hyper-parameters in order to ultimately select the one with the best performance according to a given metric. In comparison with the \"traditional way\" we saw above, `MLflow` enables us to track these experiments in a much more refined way, compatible with the *MLOps* principles.\n",
    "\n",
    "The function `log_gsvc_to_mlflow` below enables us to convert the data contained in our `GridSearchCV` object (hyperparameters, metrics, artifact..) into an `MLflow` experiment, which can then be queried using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abd9585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_gsvc_to_mlflow(gscv, mlflow_experiment_name):\n",
    "    \"\"\"Log a scikit-learn trained GridSearchCV object as an MLflow experiment.\"\"\"\n",
    "     # Set up MLFlow context\n",
    "    mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "\n",
    "    for run_idx in range(len(gscv.cv_results_[\"params\"])):\n",
    "        # For each hyperparameter combination we trained the model with, we log a run in MLflow\n",
    "        run_name = f\"run {run_idx}\"\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # Log hyperparameters\n",
    "            params = gscv.cv_results_[\"params\"][run_idx]\n",
    "            for param in params:\n",
    "                mlflow.log_param(param, params[param])\n",
    "\n",
    "            # Log fit metrics\n",
    "            scores = [score for score in gscv.cv_results_ if \"mean_test\" in score or \"std_test\" in score]\n",
    "            for score in scores:\n",
    "                mlflow.log_metric(score, gscv.cv_results_[score][run_idx])\n",
    "\n",
    "            # Log model as an artifact\n",
    "            mlflow.sklearn.log_model(gscv, \"gscv_model\")\n",
    "\n",
    "            # Log training data URL\n",
    "            mlflow.log_param(\"data_url\", DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a5f397a-1d6d-47de-94ca-29a2957c3427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/11 08:17:52 INFO mlflow.tracking.fluent: Experiment with name 'tutorial-mlflow-intro-2' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "log_gsvc_to_mlflow(gscv=pipe_gscv, mlflow_experiment_name=\"tutorial-mlflow-intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7228d7-d1ca-4188-9a7d-c3effff3e693",
   "metadata": {},
   "source": [
    "If the previous cell executed correctly, that means the experiments and in particular all the data we wanted `MLflow` to log are now available in the *tracking server*. In order to interact with these data and try to select the best model, we'll learn to use the UI. Please follow the following steps :\n",
    "- Open the UI using the URI we printed above\n",
    "- In the *Experiments* tab, open the \"tutorial-mlflow-intro\" experiment \n",
    "- Verify that there are indeed 9 runs that have been recorded, one for each hyperparameters combination\n",
    "- Open a given run and verify that you can retrieve the various information we wanted to log (hyperparameters, evaluation metrics, training data URL), check that you can download the serialized `scikit-learn` model, and check the `requirementopen the \"tutorial-mlflow-intro\" experiments.txt` file to understand how `MLflow` automatically inferred the required `Python` environment\n",
    "- Go back to the list of runs by clicking again on the \"tutorial-mlflow-intro\" experiment \n",
    "- Add additional columns using the *Columns* drop-down menu\n",
    "- Sort the models in descending order according to both the mean test F1-score and the std test F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e20f4-139c-4ac2-9c83-430552619ca4",
   "metadata": {},
   "source": [
    "### Registering a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcdaf1-9162-491f-8398-058f8c1d570b",
   "metadata": {},
   "source": [
    "In the previous section, we logged properly our experiment in the `MLflow` tracking server, which enables to compare our models and see the best performing ones in a visual way. Now, we want to be able to select a model, put it in production, and allow the other members of the projet to query it. This happens when a **move a model from the tracking server to the model registry**. To do this :\n",
    "- Click on the run with both the lowest mean test F1-score and std test F1-score\n",
    "- Click on \"Register Model\"\n",
    "- Create a New Model and give it a relevant name (e.g. \"rf-census\")\n",
    "- Move to the model registry by clicking on the \"Models\" tab\n",
    "- If everything worked correctly, you should see your model in the list of the registered models. Click on it to get the list of the registered versions of the model. For now, there is only one version as we pushed it only one time. \n",
    "- Click on \"Version 1\" to get the information on this specific version of the model. Two things are especially interesting to note :\n",
    "    - The \"Stage\" section. Here you can indicate to all members of the project what is stage of this specific model. Let's transition it to \"Production\" to indicate that is our reference model, which we want to deploy\n",
    "    - The \"Source run\" section. Here you can retrieve the run that corresponds to this model. If you click on the run id, you retrieve all the information we logged (environment, metrics, artifacts location...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39735-cd52-46bb-9559-81c6f393b3c5",
   "metadata": {},
   "source": [
    "### Querying a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d910ff9-4b0c-46f0-8d5f-47c5a6b49a79",
   "metadata": {},
   "source": [
    "As above, let's perform the final evaluation on the test set using the model we put in production. We can retrieve the model either by its version or by its stage, should it have one. We fetch the model using the `mlflow.pyfunc.load_model` function. We then have our `scikit-learn` model, which can directly be used for prediction. Let's check that we find the same final F1-score on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b7520d8-8e7c-418e-acb6-5daac6ecc2ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/model-versions/get-download-uri failed with error code 404 != 200. Response body: '<html>\r\n<head><title>404 Not Found</title></head>\r\n<body>\r\n<center><h1>404 Not Found</h1></center>\r\n<hr><center>nginx/1.19.4</center>\r\n</body>\r\n</html>\r\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf-census\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels:/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mversion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:577\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m    550\u001b[0m     model_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    551\u001b[0m     suppress_warnings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m     dst_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    553\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyFuncModel:\n\u001b[1;32m    554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    Load a model stored in Python function format.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m                     path will be created.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m    580\u001b[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    101\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:106\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[0;34m(artifact_uri)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m             requirements.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_artifact_repository_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     69\u001b[0m             artifact_uri, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     71\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:44\u001b[0m, in \u001b[0;36mModelsArtifactRepository.__init__\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m DatabricksModelsArtifactRepository(artifact_uri)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     uri \u001b[38;5;241m=\u001b[39m \u001b[43mModelsArtifactRepository\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_underlying_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:79\u001b[0m, in \u001b[0;36mModelsArtifactRepository.get_underlying_uri\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     77\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient(registry_uri\u001b[38;5;241m=\u001b[39mdatabricks_profile_uri)\n\u001b[1;32m     78\u001b[0m (name, version) \u001b[38;5;241m=\u001b[39m get_model_name_and_version(client, uri)\n\u001b[0;32m---> 79\u001b[0m download_uri \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_version_download_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/tracking/client.py:2637\u001b[0m, in \u001b[0;36mMlflowClient.get_model_version_download_uri\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_version_download_uri\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, version: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;124;03m    Get the download location in Model Registry for this model version.\u001b[39;00m\n\u001b[1;32m   2600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;124;03m        Download URI: runs:/44e04097ac364cd895f2039eaccca9ac/models/sklearn-model\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_registry_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_version_download_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/tracking/_model_registry/client.py:274\u001b[0m, in \u001b[0;36mModelRegistryClient.get_model_version_download_uri\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_version_download_uri\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, version):\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    Get the download location in Model Registry for this model version.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    :return: A single URI location that allows reads for downloading.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_version_download_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/model_registry/rest_store.py:302\u001b[0m, in \u001b[0;36mRestStore.get_model_version_download_uri\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03mGet the download location in Model Registry for this model version.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03mNOTE: For first version of Model Registry, since the models are not copied over to another\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m:return: A single URI location that allows reads for downloading.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(GetModelVersionDownloadUri(name\u001b[38;5;241m=\u001b[39mname, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(version)))\n\u001b[0;32m--> 302\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetModelVersionDownloadUri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39martifact_uri\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/store/model_registry/base_rest_store.py:42\u001b[0m, in \u001b[0;36mBaseRestStore._call_endpoint\u001b[0;34m(self, api, json_body, call_all_endpoints)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_endpoint_from_method(api)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:303\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\n\u001b[1;32m    301\u001b[0m         host_creds\u001b[38;5;241m=\u001b[39mhost_creds, endpoint\u001b[38;5;241m=\u001b[39mendpoint, method\u001b[38;5;241m=\u001b[39mmethod, json\u001b[38;5;241m=\u001b[39mjson_body\n\u001b[1;32m    302\u001b[0m     )\n\u001b[0;32m--> 303\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    305\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:233\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m failed with error code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    230\u001b[0m             endpoint,\n\u001b[1;32m    231\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    232\u001b[0m         )\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Response body: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(base_msg, response\u001b[38;5;241m.\u001b[39mtext),\n\u001b[1;32m    235\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mget_error_code(response\u001b[38;5;241m.\u001b[39mstatus_code),\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# response\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint\u001b[38;5;241m.\u001b[39mstartswith(_REST_API_PATH_PREFIX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/model-versions/get-download-uri failed with error code 404 != 200. Response body: '<html>\r\n<head><title>404 Not Found</title></head>\r\n<body>\r\n<center><h1>404 Not Found</h1></center>\r\n<hr><center>nginx/1.19.4</center>\r\n</body>\r\n</html>\r\n'"
     ]
    }
   ],
   "source": [
    "model_name = \"rf-census\"\n",
    "version = 1\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615eb88-187a-4af8-8d5f-86a907462f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c524-669f-4cc7-bb15-4a7494c0949e",
   "metadata": {},
   "source": [
    "Tagguer le modèle en prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e88bc7-d1c9-497b-8b02-debcca25a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:20 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8513551557341387\n",
      "    f1_score : 0.6448575272104684\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a7210-bf68-4785-b3e6-e21ce2333e61",
   "metadata": {},
   "source": [
    "Ajouter un second modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca23e4e6-29c7-4a17-ae68-2c25e2d78382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:23 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8514831213369847\n",
      "    f1_score : 0.6433970380384686\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "version = 2\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{version}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d553b-3309-4e51-af30-878c785f102b",
   "metadata": {},
   "source": [
    "Tagguer le nouveau modèle en staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f16f6497-ebfd-4eb7-9ee4-e5191f9763d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/25 10:20:25 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.2.1, required: cloudpickle==2.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    accuracy : 0.8514831213369847\n",
      "    f1_score : 0.6433970380384686\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model_name = \"20230118_rf_census\"\n",
    "stage = 'Staging'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print_scores(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209af40-cb49-4b75-b9ca-9a9b9de4c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
